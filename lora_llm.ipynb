{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA applied to Large Language Models\n",
    "\n",
    "[Source Article: A beginners guide to fine tuning LLM using LoRA by Zohaib Rauf](https://zohaib.me/a-beginners-guide-to-fine-tuning-llm-using-lora/)\n",
    "\n",
    "[Source Article: Llama.cpp Tutorial: A Complete Guide to Efficient LLM Inference and Implementation by Zoumana Keita](https://www.datacamp.com/tutorial/llama-cpp-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. Create the dataset, for training and evaluation\n",
    "2. Decide the metrics to use for evaluation\n",
    "3. Create a baseline with existing models\n",
    "4. Finetune using LoRA\n",
    "5. Serve the model using LLaMA.cpp with GGUF conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the dataset, for training and evaluation\n",
    "\n",
    "One strategy that can be used to create datasets is to use an existing LLM to generate it.\n",
    "Make the outputs parseable my exporting them to JSON.\n",
    "For the initial samples, its okay to use zero-shot prompting but should evaluate the data quality.\n",
    "For the remainder of the samples use few shot prompting to generate more similar samples.\n",
    "Ensure equal splits of each type of data in the train, test, and validation sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decide the metrics to use for evaluation\n",
    "\n",
    "The purpose of metrics and a baseline is to measure if the finetuned model is performing better.\n",
    "Some examples are,\n",
    "1. BLEU, uses n-gram overlap\n",
    "2. ROUGE has two variants,\n",
    "    1. ROUGE-L, longest common subsequece\n",
    "    2. ROUGE-N, N-gram overlap approach\n",
    "3. Exact match, if the generated text and target text is exactly the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a baseline with existing models\n",
    "\n",
    "Load existing models and evaluate the performace on the dataset.\n",
    "In more detail, download the GGUF and run it using LLaMA.cpp server (this supports the OpenAI format). Point the openai URL to the URL where the model is being served."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Finetune using LoRA\n",
    "\n",
    "Freeze the parameters of the original model and create a new small set of trainable parameters for the finetuning process.\n",
    "\n",
    "Some libraries for this process are,\n",
    "1. lit-gpt from Lighting AI\n",
    "2. Axolotl\n",
    "\n",
    "To prepare the dataset for finetuning, so that the data follows the format (instruction template) of the selected base LLM.\n",
    "Use the finetuning script from lit-gpt and change the data to where your data is.\n",
    "Output and checkpoints can also be changed.\n",
    "Consider adding Weights and Biases for logging.\n",
    "In the validation function, pick a random sample of from val data to check the loss of the model as it is being trained.\n",
    "To start the finetuning use an environment with GPUs, such as paperspace.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Serve the model using LLaMA.cpp with GGUF conversion\n",
    "\n",
    "Using LLaMA.cpp, we need to convert the finetuned model to GGUF format.\n",
    "Since the weights are stored seperately, we need to merge the weights from the finetuning with the ones from the original model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
