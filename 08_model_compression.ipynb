{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compression Techniques\n",
    "\n",
    "[Reference Article: Compressing Large Language Models (LLMs) by Shaw Talebi](https://towardsdatascience.com/compressing-large-language-models-llms-9f406eea5b5e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of compression LLMs is to reduce model size without sacificing performance.\n",
    "# Strategies\n",
    "There are three main ways to do so and they are independent of each other, meaning that the method can be used togheter to potential yield greater compression while maintaining comparable performace.\n",
    "1. Quantization  \n",
    "This means to reduce the precision of the parameters in the model.\n",
    "- Post-training Quantization means to train the model then quantize, improving end user inference speeds\n",
    "- Quantization Aware Training means to quantize then train, which may yield better performance on specfic downstream tasks\n",
    "2. Pruning  \n",
    "This means to remove parameters or even layers from the model.\n",
    "- Unstuctured pruning removes individual weights and leads to a greater reduction by requires specialized hardware.\n",
    "- Structured pruning remove entire sturctures and yields less reduction.\n",
    "3. Knowledge Distillation  \n",
    "This means to transfer knowledge from a larger (teacher) model to a smaller (student) model.\n",
    "- When the teacher is another model, the teacher model produces \"soft targets\" meaning the values produced are proablistic. The student \"learns\" by comparing its outputs to that of the the teacher model.\n",
    "- When we use ground truth values to train the student model, those would be called \"hard targets\" i.e in the case of binary classification 0 or 1\n",
    "- Another method is to use an existing LLM to generate Synthetic Data which can be feed into the student model.\n",
    "\n",
    "To reemphasize, these methods are independent and can be used in conjuction with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"shawhin/phishing-site-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_path = \"andrewcyeow/phishing_url_model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Drop 4 heads per layer and 2 layers\n",
    "my_config = DistilBertConfig(n_heads=8, n_layers=4)\n",
    "\n",
    "student_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", config=my_config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 450/450 [00:00<00:00, 3160.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_data = data.map(preprocess_function, batched=True)\n",
    "tokenized_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Function\n",
    "\n",
    "This loss function combines the distillation loss from the soft targets produced by the teacher model and the hard loss from comparing the model outputs with the group truth values. Alpha is the parameter used to control the relative weight of distillation loss to hard loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, \n",
    "                      true_labels, temperature, alpha):\n",
    "    # Compute soft targets from teacher logits\n",
    "    soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=1)\n",
    "    student_soft = nn.functional.log_softmax(student_logits / temperature, dim=1)\n",
    "\n",
    "    # KL Divergence loss for distillation\n",
    "    distill_loss = nn.functional.kl_div(student_soft, \n",
    "                                    soft_targets, \n",
    "                                    reduction='batchmean') * (temperature ** 2)\n",
    "\n",
    "    # Cross-entropy loss for hard labels\n",
    "    hard_loss = nn.CrossEntropyLoss()(student_logits, true_labels)\n",
    "\n",
    "    # Combine losses\n",
    "    loss = alpha * distill_loss + (1.0 - alpha) * hard_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters, Optimizers, and Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "num_epochs = 5\n",
    "temperature = 2.0\n",
    "alpha = 0.5\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
    "\n",
    "# create training data loader\n",
    "dataloader = DataLoader(tokenized_data['train'], batch_size=batch_size)\n",
    "# create testing data loader\n",
    "test_dataloader = DataLoader(tokenized_data['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed with loss: 0.08567795157432556\n",
      "Teacher (test) - Accuracy: 0.8644, Precision: 0.8962, Recall: 0.8297, F1 Score: 0.8617\n",
      "Student (test) - Accuracy: 0.9156, Precision: 0.9099, Recall: 0.9258, F1 Score: 0.9177\n",
      "\n",
      "\n",
      "Epoch 2 completed with loss: 0.055420562624931335\n",
      "Teacher (test) - Accuracy: 0.8644, Precision: 0.8962, Recall: 0.8297, F1 Score: 0.8617\n",
      "Student (test) - Accuracy: 0.9156, Precision: 0.9361, Recall: 0.8952, F1 Score: 0.9152\n",
      "\n",
      "\n",
      "Epoch 3 completed with loss: 0.07385220378637314\n",
      "Teacher (test) - Accuracy: 0.8644, Precision: 0.8962, Recall: 0.8297, F1 Score: 0.8617\n",
      "Student (test) - Accuracy: 0.9067, Precision: 0.8912, Recall: 0.9301, F1 Score: 0.9103\n",
      "\n",
      "\n",
      "Epoch 4 completed with loss: 0.16781014204025269\n",
      "Teacher (test) - Accuracy: 0.8644, Precision: 0.8962, Recall: 0.8297, F1 Score: 0.8617\n",
      "Student (test) - Accuracy: 0.9000, Precision: 0.9381, Recall: 0.8603, F1 Score: 0.8975\n",
      "\n",
      "\n",
      "Epoch 5 completed with loss: 0.071306973695755\n",
      "Teacher (test) - Accuracy: 0.8644, Precision: 0.8962, Recall: 0.8297, F1 Score: 0.8617\n",
      "Student (test) - Accuracy: 0.9133, Precision: 0.9439, Recall: 0.8821, F1 Score: 0.9120\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# put student model in train mode\n",
    "student_model.train()\n",
    "\n",
    "# train model\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Prepare inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Disable gradient calculation for teacher model\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask)\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_outputs = student_model(input_ids, attention_mask=attention_mask)\n",
    "        student_logits = student_outputs.logits\n",
    "\n",
    "        # Compute the distillation loss\n",
    "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed with loss: {loss.item()}\")\n",
    "\n",
    "    # Evaluate the teacher model\n",
    "    teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, test_dataloader, device)\n",
    "\n",
    "    print(f\"Teacher (test) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
    "\n",
    "    # Evaluate the student model\n",
    "    student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, test_dataloader, device)\n",
    "    \n",
    "    print(f\"Student (test) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # put student model back into train mode\n",
    "    student_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model on an Independent Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher (test) - Accuracy: 0.8800, Precision: 0.9091, Recall: 0.8444, F1 Score: 0.8756\n",
      "Student (test) - Accuracy: 0.9222, Precision: 0.9481, Recall: 0.8933, F1 Score: 0.9199\n"
     ]
    }
   ],
   "source": [
    "validation_dataloader = DataLoader(tokenized_data['validation'], batch_size=8)\n",
    "\n",
    "teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, validation_dataloader, device)\n",
    "print(f\"Teacher (test) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
    "\n",
    "student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, validation_dataloader, device)\n",
    "print(f\"Student (test) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the Student Model to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 211M/211M [00:10<00:00, 20.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/andrewcyeow/phishing_url_student_model/commit/dd8b098c4b71e643159e9253749b2179c8a69009', commit_message='Upload DistilBertForSequenceClassification', commit_description='', oid='dd8b098c4b71e643159e9253749b2179c8a69009', pr_url=None, repo_url=RepoUrl('https://huggingface.co/andrewcyeow/phishing_url_student_model', endpoint='https://huggingface.co', repo_type='model', repo_id='andrewcyeow/phishing_url_student_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.push_to_hub(\"andrewcyeow/phishing_url_student_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model in using QLoRA\n",
    "- store model parameters using the 4-bit NormalFloat data type\n",
    "- bfloat16 for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"andrewcyeow/phishing_url_student_model\"\n",
    "\n",
    "# load model in model as 4-bit\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model_nf4 = AutoModelForSequenceClassification.from_pretrained(model_id, device_map=device, quantization_config=nf4_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-quantization Performance\n",
      "Accuracy: 0.9289, Precision: 0.9573, Recall: 0.8978, F1 Score: 0.9266\n"
     ]
    }
   ],
   "source": [
    "quantized_accuracy, quantized_precision, quantized_recall, quantized_f1 = evaluate_model(model_nf4, validation_dataloader, device)\n",
    "\n",
    "print(\"Post-quantization Performance\")\n",
    "print(f\"Accuracy: {quantized_accuracy:.4f}, Precision: {quantized_precision:.4f}, Recall: {quantized_recall:.4f}, F1 Score: {quantized_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
