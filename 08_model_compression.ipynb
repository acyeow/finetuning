{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compression Techniques\n",
    "\n",
    "[Reference Article: Compressing Large Language Models (LLMs) by Shaw Talebi](https://towardsdatascience.com/compressing-large-language-models-llms-9f406eea5b5e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of compression LLMs is to reduce model size without sacificing performance.\n",
    "# Strageties\n",
    "There are three main ways to do so and they are independent of each other, meaning that the method can be used togheter to potential yield greater compression while maintaining comparable performace.\n",
    "1. Quantization  \n",
    "This means to reduce the precision of the parameters in the model.\n",
    "- Post-training Quantization means to train the model then quantize, improving end user inference speeds\n",
    "- Quantization Aware Training means to quantize then train, which may yield better performance on specfic downstream tasks\n",
    "2. Pruning  \n",
    "This means to remove parameters or even layers from the model.\n",
    "- Unstuctured pruning removes individual weights and leads to a greater reduction by requires specialized hardware.\n",
    "- Structured pruning remove entire sturctures and yields less reduction.\n",
    "3. Knowledge Distillation  \n",
    "This means to transfer knowledge from a larger (teacher) model to a smaller (student) model.\n",
    "- When the teacher is another model, the teacher model produces \"soft targets\" meaning the values produced are proablistic. The student \"learns\" by comparing its outputs to that of the the teacher model.\n",
    "- When we use ground truth values to train the student model, those would be called \"hard targets\" i.e in the case of binary classification 0 or 1\n",
    "- Another method is to use an existing LLM to generate Synthetic Data which can be feed into the student model.\n",
    "\n",
    "To reemphasize, these methods are independent and can be used in conjuction with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
